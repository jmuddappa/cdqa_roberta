{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roberta_cdqa.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMofnTAo+S3SC0uBw3eJKGh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmuddappa/cdqa_roberta/blob/master/roberta_cdqa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmGbRIVP6C4l",
        "colab_type": "code",
        "outputId": "b92482ad-92c4-4d2f-f08a-70c30e8d6e52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!git clone https://github.com/pytorch/fairseq"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 13505, done.\u001b[K\n",
            "remote: Total 13505 (delta 0), reused 0 (delta 0), pack-reused 13505\u001b[K\n",
            "Receiving objects: 100% (13505/13505), 6.28 MiB | 21.66 MiB/s, done.\n",
            "Resolving deltas: 100% (9942/9942), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sORWamKjD1Gs",
        "colab_type": "code",
        "outputId": "6a0cd432-961b-4225-dcdf-fb6d518eef48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "%cd fairseq\n",
        "!pip install --editable ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fairseq\n",
            "Obtaining file:///content/fairseq\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.14.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (0.29.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.17.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (2019.12.20)\n",
            "Collecting sacrebleu\n",
            "  Downloading https://files.pythonhosted.org/packages/45/31/1a135b964c169984b27fb2f7a50280fa7f8e6d9d404d8a9e596180487fd1/sacrebleu-1.4.3-py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (4.28.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.9.0) (2.19)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/91/db/7bc703c0760df726839e0699b7f78a4d8217fdc9c7fcb1b51b39c5a22a4e/portalocker-1.5.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->fairseq==0.9.0) (3.6.6)\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed fairseq portalocker-1.5.2 sacrebleu-1.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj2LqLGB6P8m",
        "colab_type": "code",
        "outputId": "aa1c2488-5fd9-410b-b4ea-662d21c2a0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz\n",
        "!tar -xvf /content/fairseq/roberta.large.tar.gz\n",
        "!bash examples/roberta/commonsense_qa/download_cqa_data.sh\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-14 22:06:36--  https://dl.fbaipublicfiles.com/fairseq/models/roberta.large.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 655283069 (625M) [application/gzip]\n",
            "Saving to: ‘roberta.large.tar.gz’\n",
            "\n",
            "roberta.large.tar.g 100%[===================>] 624.93M  36.2MB/s    in 18s     \n",
            "\n",
            "2020-02-14 22:06:54 (35.2 MB/s) - ‘roberta.large.tar.gz’ saved [655283069/655283069]\n",
            "\n",
            "roberta.large/\n",
            "roberta.large/dict.txt\n",
            "roberta.large/model.pt\n",
            "roberta.large/NOTE\n",
            "--2020-02-14 22:07:07--  https://s3.amazonaws.com/commensenseqa/train_rand_split.jsonl\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.137.198\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.137.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3785890 (3.6M) [binary/octet-stream]\n",
            "Saving to: ‘data/CommonsenseQA/train.jsonl’\n",
            "\n",
            "data/CommonsenseQA/ 100%[===================>]   3.61M  14.7MB/s    in 0.2s    \n",
            "\n",
            "2020-02-14 22:07:08 (14.7 MB/s) - ‘data/CommonsenseQA/train.jsonl’ saved [3785890/3785890]\n",
            "\n",
            "--2020-02-14 22:07:08--  https://s3.amazonaws.com/commensenseqa/dev_rand_split.jsonl\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.45.238\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.45.238|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 471653 (461K) [binary/octet-stream]\n",
            "Saving to: ‘data/CommonsenseQA/valid.jsonl’\n",
            "\n",
            "data/CommonsenseQA/ 100%[===================>] 460.60K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-02-14 22:07:08 (3.90 MB/s) - ‘data/CommonsenseQA/valid.jsonl’ saved [471653/471653]\n",
            "\n",
            "--2020-02-14 22:07:08--  https://s3.amazonaws.com/commensenseqa/test_rand_split_no_answers.jsonl\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.45.238\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.45.238|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 423148 (413K) [binary/octet-stream]\n",
            "Saving to: ‘data/CommonsenseQA/test.jsonl’\n",
            "\n",
            "data/CommonsenseQA/ 100%[===================>] 413.23K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-02-14 22:07:08 (3.51 MB/s) - ‘data/CommonsenseQA/test.jsonl’ saved [423148/423148]\n",
            "\n",
            "--2020-02-14 22:07:08--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.6.166, 104.20.22.166, 2606:4700:10::6814:6a6, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.6.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 603290 (589K) [text/plain]\n",
            "Saving to: ‘data/CommonsenseQA/dict.txt’\n",
            "\n",
            "data/CommonsenseQA/ 100%[===================>] 589.15K  2.20MB/s    in 0.3s    \n",
            "\n",
            "2020-02-14 22:07:09 (2.20 MB/s) - ‘data/CommonsenseQA/dict.txt’ saved [603290/603290]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqVPGBQf6WoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74d8b19a-3adb-45c6-d6a8-1eb99125b5a2"
      },
      "source": [
        "%env MAX_UPDATES=3000\n",
        "%env WARMUP_UPDATES=150\n",
        "%env LR=1e-05\n",
        "%env MAX_SENTENCES=8\n",
        "%env SEED=1\n",
        "%env ROBERTA_PATH=/roberta.large/model.pt\n",
        "%env DATA_DIR=/content/fairseq/data/CommonsenseQA\n",
        "\n",
        "%env FAIRSEQ_PATH=/content/fairseq\n",
        "%env FAIRSEQ_USER_DIR=/content/fairseq/examples/roberta/commonsense_qa\n",
        "\n",
        "!CUDA_VISIBLE_DEVICES=0 fairseq-train --fp16 --ddp-backend=no_c10d $DATA_DIR --user-dir $FAIRSEQ_USER_DIR \\\n",
        "    --restore-file $ROBERTA_PATH \\\n",
        "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
        "    --no-epoch-checkpoints --no-last-checkpoints --no-save-optimizer-state \\\n",
        "    --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric \\\n",
        "    --task commonsense_qa --init-token 0 --bpe gpt2 \\\n",
        "    --arch roberta_large --max-positions 512 \\\n",
        "    --dropout 0.1 --attention-dropout 0.1 --weight-decay 0.01 \\\n",
        "    --criterion sentence_ranking --num-classes 5 \\\n",
        "    --optimizer adam --adam-betas '(0.9, 0.98)' --adam-eps 1e-06 --clip-norm 0.0 \\\n",
        "    --lr-scheduler polynomial_decay --lr $LR \\\n",
        "    --warmup-updates $WARMUP_UPDATES --total-num-update $MAX_UPDATES \\\n",
        "    --max-sentences $MAX_SENTENCES \\\n",
        "    --max-update $MAX_UPDATES \\\n",
        "    --log-format simple --log-interval 25 \\\n",
        "    --seed $SEED"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: MAX_UPDATES=3000\n",
            "env: WARMUP_UPDATES=150\n",
            "env: LR=1e-05\n",
            "env: MAX_SENTENCES=8\n",
            "env: SEED=1\n",
            "env: ROBERTA_PATH=/roberta.large/model.pt\n",
            "env: DATA_DIR=/content/fairseq/data/CommonsenseQA\n",
            "env: FAIRSEQ_PATH=/content/fairseq\n",
            "env: FAIRSEQ_USER_DIR=/content/fairseq/examples/roberta/commonsense_qa\n",
            "2020-02-14 22:07:11 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, all_gather_list_size=16384, arch='roberta_large', attention_dropout=0.1, best_checkpoint_metric='accuracy', bpe='gpt2', broadcast_buffers=False, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='sentence_ranking', curriculum=0, data='/content/fairseq/data/CommonsenseQA', dataset_impl=None, ddp_backend='no_c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=24, encoder_layers_to_keep=None, end_learning_rate=0.0, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gpt2_encoder_json='https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json', gpt2_vocab_bpe='https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe', init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, log_format='simple', log_interval=25, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_positions=512, max_sentences=8, max_sentences_valid=8, max_tokens=None, max_tokens_valid=None, max_update=3000, maximize_best_checkpoint_metric=True, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, no_epoch_checkpoints=True, no_last_checkpoints=True, no_progress_bar=False, no_save=False, no_save_optimizer_state=True, num_classes=5, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, ranking_head_name='sentence_classification_head', required_batch_size_multiple=8, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='/roberta.large/model.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, save_predictions=None, seed=1, sentence_avg=False, skip_invalid_size_inputs_valid_test=False, task='commonsense_qa', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=3000, train_subset='train', update_freq=[1], use_bmuf=False, use_old_adam=False, user_dir='/content/fairseq/examples/roberta/commonsense_qa', valid_subset='valid', validate_interval=1, warmup_updates=150, weight_decay=0.01)\n",
            "| dictionary: 50265 types\n",
            "2020-02-14 22:07:11 | INFO | fairseq.file_utils | https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json not found in cache, downloading to /tmp/tmp8xzxcrxn\n",
            "1042301B [00:00, 2532022.79B/s]\n",
            "2020-02-14 22:07:12 | INFO | fairseq.file_utils | copying /tmp/tmp8xzxcrxn to cache at /root/.cache/torch/pytorch_fairseq/e2aab4d600e7568c2d88fc7732130ccc815ea84ec63906cb0913c7a3a4906a2e.0f323dfaed92d080380e63f0291d0f31adfa8c61a62cbcb3cb8114f061be27f7\n",
            "2020-02-14 22:07:12 | INFO | fairseq.file_utils | creating metadata file for /root/.cache/torch/pytorch_fairseq/e2aab4d600e7568c2d88fc7732130ccc815ea84ec63906cb0913c7a3a4906a2e.0f323dfaed92d080380e63f0291d0f31adfa8c61a62cbcb3cb8114f061be27f7\n",
            "2020-02-14 22:07:12 | INFO | fairseq.file_utils | removing temp file /tmp/tmp8xzxcrxn\n",
            "2020-02-14 22:07:12 | INFO | fairseq.file_utils | https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe not found in cache, downloading to /tmp/tmpsfwlas3e\n",
            "456318B [00:00, 2006725.39B/s]\n",
            "2020-02-14 22:07:13 | INFO | fairseq.file_utils | copying /tmp/tmpsfwlas3e to cache at /root/.cache/torch/pytorch_fairseq/b04a6d337c09f464fe8f0df1d3524db88a597007d63f05d97e437f65840cdba5.939bed25cbdab15712bac084ee713d6c78e221c5156c68cb0076b03f5170600f\n",
            "2020-02-14 22:07:13 | INFO | fairseq.file_utils | creating metadata file for /root/.cache/torch/pytorch_fairseq/b04a6d337c09f464fe8f0df1d3524db88a597007d63f05d97e437f65840cdba5.939bed25cbdab15712bac084ee713d6c78e221c5156c68cb0076b03f5170600f\n",
            "2020-02-14 22:07:13 | INFO | fairseq.file_utils | removing temp file /tmp/tmpsfwlas3e\n",
            "| Loaded valid with 1221 samples\n",
            "2020-02-14 22:07:24 | INFO | fairseq_cli.train | RobertaModel(\n",
            "  (decoder): RobertaEncoder(\n",
            "    (sentence_encoder): TransformerSentenceEncoder(\n",
            "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
            "      (embed_positions): LearnedPositionalEmbedding(514, 1024, padding_idx=1)\n",
            "      (layers): ModuleList(\n",
            "        (0): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (1): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (2): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (3): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (4): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (5): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (6): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (7): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (8): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (9): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (10): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (11): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (12): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (13): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (14): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (15): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (16): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (17): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (18): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (19): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (20): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (21): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (22): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "        (23): TransformerSentenceEncoderLayer(\n",
            "          (self_attn): MultiheadAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (emb_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (lm_head): RobertaLMHead(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (classification_heads): ModuleDict(\n",
            "    (sentence_classification_head): RobertaClassificationHead(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (dropout): Dropout(p=0.0, inplace=False)\n",
            "      (out_proj): Linear(in_features=1024, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2020-02-14 22:07:24 | INFO | fairseq_cli.train | model roberta_large, criterion SentenceRankingCriterion\n",
            "2020-02-14 22:07:24 | INFO | fairseq_cli.train | num. model params: 356461658 (num. trained: 356461658)\n",
            "2020-02-14 22:07:35 | INFO | fairseq_cli.train | training on 1 GPUs\n",
            "2020-02-14 22:07:35 | INFO | fairseq_cli.train | max tokens per GPU = None and max sentences per GPU = 8\n",
            "2020-02-14 22:07:35 | INFO | fairseq.trainer | no existing checkpoint found /roberta.large/model.pt\n",
            "2020-02-14 22:07:35 | INFO | fairseq.trainer | loading train data for epoch 0\n",
            "| Loaded train with 9741 samples\n",
            "2020-02-14 22:07:58 | INFO | train | epoch 001:     24 / 1218 loss=2.341, nll_loss=0.097, accuracy=21.5, wps=349.9, ups=1.84, wpb=192.3, bsz=8, num_updates=25, lr=1.66667e-06, gnorm=11.968, clip=0, oom=0, loss_scale=128, train_wall=14, ppl=1.07, wall=23\n",
            "2020-02-14 22:08:12 | INFO | train | epoch 001:     49 / 1218 loss=2.345, nll_loss=0.098, accuracy=21.25, wps=351.8, ups=1.84, wpb=192.1, bsz=8, num_updates=50, lr=3.33333e-06, gnorm=11.47, clip=0, oom=0, loss_scale=128, train_wall=28, ppl=1.07, wall=37\n",
            "2020-02-14 22:08:25 | INFO | train | epoch 001:     74 / 1218 loss=2.339, nll_loss=0.098, accuracy=19.5, wps=348.9, ups=1.83, wpb=191.5, bsz=8, num_updates=75, lr=5e-06, gnorm=10.39, clip=0, oom=0, loss_scale=128, train_wall=41, ppl=1.07, wall=50\n",
            "2020-02-14 22:08:39 | INFO | train | epoch 001:     99 / 1218 loss=2.333, nll_loss=0.097, accuracy=20.125, wps=350.5, ups=1.82, wpb=192.9, bsz=8, num_updates=100, lr=6.66667e-06, gnorm=9.518, clip=0, oom=0, loss_scale=128, train_wall=55, ppl=1.07, wall=64\n",
            "2020-02-14 22:08:53 | INFO | train | epoch 001:    124 / 1218 loss=2.33, nll_loss=0.097, accuracy=19.700000762939453, wps=350.1, ups=1.82, wpb=192.6, bsz=8, num_updates=125, lr=8.33333e-06, gnorm=8.869, clip=0, oom=0, loss_scale=128, train_wall=69, ppl=1.07, wall=78\n",
            "2020-02-14 22:09:06 | INFO | train | epoch 001:    149 / 1218 loss=2.33, nll_loss=0.097, accuracy=19.41666603088379, wps=351.8, ups=1.83, wpb=192.9, bsz=8, num_updates=150, lr=1e-05, gnorm=8.308, clip=0, oom=0, loss_scale=128, train_wall=82, ppl=1.07, wall=92\n",
            "2020-02-14 22:09:20 | INFO | train | epoch 001:    174 / 1218 loss=2.33, nll_loss=0.097, accuracy=19.214284896850586, wps=350, ups=1.82, wpb=192.6, bsz=8, num_updates=175, lr=9.91228e-06, gnorm=7.823, clip=0, oom=0, loss_scale=128, train_wall=96, ppl=1.07, wall=106\n",
            "2020-02-14 22:09:34 | INFO | train | epoch 001:    199 / 1218 loss=2.329, nll_loss=0.097, accuracy=18.875, wps=349.4, ups=1.82, wpb=192.5, bsz=8, num_updates=200, lr=9.82456e-06, gnorm=7.42, clip=0, oom=0, loss_scale=128, train_wall=110, ppl=1.07, wall=119\n",
            "2020-02-14 22:09:48 | INFO | train | epoch 001:    224 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.66666603088379, wps=348.4, ups=1.81, wpb=192.1, bsz=8, num_updates=225, lr=9.73684e-06, gnorm=7.087, clip=0, oom=0, loss_scale=128, train_wall=123, ppl=1.07, wall=133\n",
            "2020-02-14 22:10:03 | INFO | train | epoch 001:    249 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.149999618530273, wps=346.4, ups=1.81, wpb=192, bsz=8, num_updates=250, lr=9.64912e-06, gnorm=6.814, clip=0, oom=0, loss_scale=128, train_wall=138, ppl=1.07, wall=148\n",
            "2020-02-14 22:10:17 | INFO | train | epoch 001:    274 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.863636016845703, wps=346.8, ups=1.8, wpb=192.3, bsz=8, num_updates=275, lr=9.5614e-06, gnorm=6.573, clip=0, oom=0, loss_scale=128, train_wall=151, ppl=1.07, wall=162\n",
            "2020-02-14 22:10:30 | INFO | train | epoch 001:    299 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.83333396911621, wps=347.4, ups=1.81, wpb=192.3, bsz=8, num_updates=300, lr=9.47368e-06, gnorm=6.34, clip=0, oom=0, loss_scale=128, train_wall=165, ppl=1.07, wall=175\n",
            "2020-02-14 22:10:44 | INFO | train | epoch 001:    324 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.0, wps=347.4, ups=1.81, wpb=191.9, bsz=8, num_updates=325, lr=9.38596e-06, gnorm=6.128, clip=0, oom=0, loss_scale=128, train_wall=178, ppl=1.07, wall=189\n",
            "2020-02-14 22:10:57 | INFO | train | epoch 001:    349 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.821428298950195, wps=347.2, ups=1.81, wpb=191.7, bsz=8, num_updates=350, lr=9.29825e-06, gnorm=5.945, clip=0, oom=0, loss_scale=128, train_wall=192, ppl=1.07, wall=202\n",
            "2020-02-14 22:11:11 | INFO | train | epoch 001:    374 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.899999618530273, wps=348.3, ups=1.82, wpb=191.8, bsz=8, num_updates=375, lr=9.21053e-06, gnorm=5.777, clip=0, oom=0, loss_scale=128, train_wall=205, ppl=1.07, wall=216\n",
            "2020-02-14 22:11:24 | INFO | train | epoch 001:    399 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.71875, wps=348.6, ups=1.82, wpb=191.5, bsz=8, num_updates=400, lr=9.12281e-06, gnorm=5.622, clip=0, oom=0, loss_scale=128, train_wall=218, ppl=1.07, wall=229\n",
            "2020-02-14 22:11:38 | INFO | train | epoch 001:    424 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.705883026123047, wps=348.8, ups=1.82, wpb=191.6, bsz=8, num_updates=425, lr=9.03509e-06, gnorm=5.482, clip=0, oom=0, loss_scale=128, train_wall=232, ppl=1.07, wall=243\n",
            "2020-02-14 22:11:52 | INFO | train | epoch 001:    449 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.91666603088379, wps=348.3, ups=1.82, wpb=191.9, bsz=8, num_updates=450, lr=8.94737e-06, gnorm=5.355, clip=0, oom=0, loss_scale=128, train_wall=246, ppl=1.07, wall=257\n",
            "2020-02-14 22:12:06 | INFO | train | epoch 001:    474 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.105262756347656, wps=347.8, ups=1.81, wpb=191.9, bsz=8, num_updates=475, lr=8.85965e-06, gnorm=5.241, clip=0, oom=0, loss_scale=128, train_wall=260, ppl=1.07, wall=271\n",
            "2020-02-14 22:12:20 | INFO | train | epoch 001:    499 / 1218 loss=2.327, nll_loss=0.097, accuracy=20.149999618530273, wps=348.1, ups=1.81, wpb=192.2, bsz=8, num_updates=500, lr=8.77193e-06, gnorm=5.144, clip=0, oom=0, loss_scale=128, train_wall=274, ppl=1.07, wall=285\n",
            "2020-02-14 22:12:34 | INFO | train | epoch 001:    524 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.119047164916992, wps=347.9, ups=1.81, wpb=192.1, bsz=8, num_updates=525, lr=8.68421e-06, gnorm=5.057, clip=0, oom=0, loss_scale=128, train_wall=287, ppl=1.07, wall=299\n",
            "2020-02-14 22:12:48 | INFO | train | epoch 001:    549 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.06818199157715, wps=347.6, ups=1.81, wpb=192, bsz=8, num_updates=550, lr=8.59649e-06, gnorm=4.971, clip=0, oom=0, loss_scale=128, train_wall=301, ppl=1.07, wall=313\n",
            "2020-02-14 22:13:02 | INFO | train | epoch 001:    574 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.978260040283203, wps=347.9, ups=1.81, wpb=192.4, bsz=8, num_updates=575, lr=8.50877e-06, gnorm=4.885, clip=0, oom=0, loss_scale=128, train_wall=315, ppl=1.07, wall=327\n",
            "2020-02-14 22:13:16 | INFO | train | epoch 001:    599 / 1218 loss=2.327, nll_loss=0.097, accuracy=20.0625, wps=347.4, ups=1.81, wpb=192.1, bsz=8, num_updates=600, lr=8.42105e-06, gnorm=4.812, clip=0, oom=0, loss_scale=128, train_wall=329, ppl=1.07, wall=341\n",
            "2020-02-14 22:13:30 | INFO | train | epoch 001:    624 / 1218 loss=2.327, nll_loss=0.097, accuracy=20.079999923706055, wps=347.4, ups=1.81, wpb=192, bsz=8, num_updates=625, lr=8.33333e-06, gnorm=4.746, clip=0, oom=0, loss_scale=128, train_wall=342, ppl=1.07, wall=355\n",
            "2020-02-14 22:13:44 | INFO | train | epoch 001:    649 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.846153259277344, wps=347.2, ups=1.81, wpb=192, bsz=8, num_updates=650, lr=8.24561e-06, gnorm=4.681, clip=0, oom=0, loss_scale=128, train_wall=356, ppl=1.07, wall=369\n",
            "2020-02-14 22:13:58 | INFO | train | epoch 001:    674 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.94444465637207, wps=347.4, ups=1.81, wpb=192.2, bsz=8, num_updates=675, lr=8.15789e-06, gnorm=4.618, clip=0, oom=0, loss_scale=128, train_wall=370, ppl=1.07, wall=383\n",
            "2020-02-14 22:14:12 | INFO | train | epoch 001:    699 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.0, wps=346.7, ups=1.81, wpb=192, bsz=8, num_updates=700, lr=8.07018e-06, gnorm=4.558, clip=0, oom=0, loss_scale=128, train_wall=384, ppl=1.07, wall=397\n",
            "2020-02-14 22:14:26 | INFO | train | epoch 001:    724 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.965517044067383, wps=346.3, ups=1.81, wpb=191.9, bsz=8, num_updates=725, lr=7.98246e-06, gnorm=4.506, clip=0, oom=0, loss_scale=128, train_wall=398, ppl=1.07, wall=411\n",
            "2020-02-14 22:14:40 | INFO | train | epoch 001:    749 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.950000762939453, wps=346.3, ups=1.8, wpb=192, bsz=8, num_updates=750, lr=7.89474e-06, gnorm=4.458, clip=0, oom=0, loss_scale=128, train_wall=412, ppl=1.07, wall=425\n",
            "2020-02-14 22:14:54 | INFO | train | epoch 001:    774 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.887096405029297, wps=345.9, ups=1.8, wpb=191.8, bsz=8, num_updates=775, lr=7.80702e-06, gnorm=4.412, clip=0, oom=0, loss_scale=128, train_wall=426, ppl=1.07, wall=439\n",
            "2020-02-14 22:15:08 | INFO | train | epoch 001:    799 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.884321212768555, wps=345.9, ups=1.8, wpb=191.8, bsz=8, num_updates=800, lr=7.7193e-06, gnorm=4.37, clip=0, oom=0, loss_scale=128, train_wall=439, ppl=1.07, wall=453\n",
            "2020-02-14 22:15:21 | INFO | train | epoch 001:    824 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.827194213867188, wps=346.2, ups=1.81, wpb=191.8, bsz=8, num_updates=825, lr=7.63158e-06, gnorm=4.326, clip=0, oom=0, loss_scale=128, train_wall=453, ppl=1.07, wall=466\n",
            "2020-02-14 22:15:35 | INFO | train | epoch 001:    849 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.84699058532715, wps=346.1, ups=1.8, wpb=191.8, bsz=8, num_updates=850, lr=7.54386e-06, gnorm=4.282, clip=0, oom=0, loss_scale=128, train_wall=466, ppl=1.07, wall=480\n",
            "2020-02-14 22:15:49 | INFO | train | epoch 001:    874 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.979991912841797, wps=346.3, ups=1.8, wpb=192, bsz=8, num_updates=875, lr=7.45614e-06, gnorm=4.238, clip=0, oom=0, loss_scale=128, train_wall=480, ppl=1.07, wall=494\n",
            "2020-02-14 22:16:03 | INFO | train | epoch 001:    899 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.980546951293945, wps=346.4, ups=1.8, wpb=192, bsz=8, num_updates=900, lr=7.36842e-06, gnorm=4.198, clip=0, oom=0, loss_scale=128, train_wall=494, ppl=1.07, wall=508\n",
            "2020-02-14 22:16:17 | INFO | train | epoch 001:    924 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.03514862060547, wps=346.6, ups=1.81, wpb=192, bsz=8, num_updates=925, lr=7.2807e-06, gnorm=4.16, clip=0, oom=0, loss_scale=128, train_wall=507, ppl=1.07, wall=522\n",
            "2020-02-14 22:16:31 | INFO | train | epoch 001:    949 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.073713302612305, wps=346.3, ups=1.8, wpb=192, bsz=8, num_updates=950, lr=7.19298e-06, gnorm=4.123, clip=0, oom=0, loss_scale=128, train_wall=521, ppl=1.07, wall=536\n",
            "2020-02-14 22:16:45 | INFO | train | epoch 001:    974 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.135950088500977, wps=346.9, ups=1.8, wpb=192.3, bsz=8, num_updates=975, lr=7.10526e-06, gnorm=4.087, clip=0, oom=0, loss_scale=128, train_wall=535, ppl=1.07, wall=550\n",
            "2020-02-14 22:16:59 | INFO | train | epoch 001:    999 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.082530975341797, wps=346.9, ups=1.8, wpb=192.5, bsz=8, num_updates=1000, lr=7.01754e-06, gnorm=4.054, clip=0, oom=0, loss_scale=128, train_wall=549, ppl=1.07, wall=564\n",
            "2020-02-14 22:17:13 | INFO | train | epoch 001:   1024 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.117116928100586, wps=346.5, ups=1.8, wpb=192.5, bsz=8, num_updates=1025, lr=6.92982e-06, gnorm=4.024, clip=0, oom=0, loss_scale=128, train_wall=564, ppl=1.07, wall=578\n",
            "2020-02-14 22:17:27 | INFO | train | epoch 001:   1049 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.09050941467285, wps=346.8, ups=1.8, wpb=192.6, bsz=8, num_updates=1050, lr=6.84211e-06, gnorm=3.996, clip=0, oom=0, loss_scale=128, train_wall=577, ppl=1.07, wall=592\n",
            "2020-02-14 22:17:41 | INFO | train | epoch 001:   1074 / 1218 loss=2.327, nll_loss=0.097, accuracy=20.088403701782227, wps=347.1, ups=1.8, wpb=192.6, bsz=8, num_updates=1075, lr=6.75439e-06, gnorm=3.969, clip=0, oom=0, loss_scale=128, train_wall=590, ppl=1.07, wall=606\n",
            "2020-02-14 22:17:54 | INFO | train | epoch 001:   1099 / 1218 loss=2.327, nll_loss=0.097, accuracy=20.143230438232422, wps=347.5, ups=1.8, wpb=192.7, bsz=8, num_updates=1100, lr=6.66667e-06, gnorm=3.944, clip=0, oom=0, loss_scale=128, train_wall=604, ppl=1.07, wall=619\n",
            "2020-02-14 22:18:08 | INFO | train | epoch 001:   1124 / 1218 loss=2.327, nll_loss=0.097, accuracy=20.228965759277344, wps=347.5, ups=1.8, wpb=192.7, bsz=8, num_updates=1125, lr=6.57895e-06, gnorm=3.92, clip=0, oom=0, loss_scale=128, train_wall=618, ppl=1.07, wall=633\n",
            "2020-02-14 22:18:22 | INFO | train | epoch 001:   1149 / 1218 loss=2.327, nll_loss=0.097, accuracy=20.267478942871094, wps=347.4, ups=1.8, wpb=192.6, bsz=8, num_updates=1150, lr=6.49123e-06, gnorm=3.899, clip=0, oom=0, loss_scale=128, train_wall=631, ppl=1.07, wall=647\n",
            "2020-02-14 22:18:35 | INFO | train | epoch 001:   1174 / 1218 loss=2.327, nll_loss=0.096, accuracy=20.26178550720215, wps=348.1, ups=1.8, wpb=192.9, bsz=8, num_updates=1175, lr=6.40351e-06, gnorm=3.88, clip=0, oom=0, loss_scale=128, train_wall=645, ppl=1.07, wall=660\n",
            "2020-02-14 22:18:49 | INFO | train | epoch 001:   1199 / 1218 loss=2.327, nll_loss=0.096, accuracy=20.22507095336914, wps=348.2, ups=1.8, wpb=192.9, bsz=8, num_updates=1200, lr=6.31579e-06, gnorm=3.862, clip=0, oom=0, loss_scale=128, train_wall=658, ppl=1.07, wall=674\n",
            "2020-02-14 22:18:59 | INFO | train | epoch 001 | loss 2.327 | nll_loss 0.096 | accuracy 20.172466278076172 | wps 348.2 | ups 1.8 | wpb 193 | bsz 8 | num_updates 1218 | lr 6.25263e-06 | gnorm 3.849 | clip 0 | oom 0 | loss_scale 128 | train_wall 668 | ppl 1.07 | wall 684\n",
            "2020-02-14 22:19:18 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 2.322 | nll_loss 0.097 | accuracy 17.362817764282227 | wps 1523.4 | wpb 191 | bsz 8 | ppl 1.07 | num_updates 1218\n",
            "2020-02-14 22:19:20 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 1218 updates, score 17.362817764282227) (writing took 2.0317795649998516 seconds)\n",
            "2020-02-14 22:19:34 | INFO | train | epoch 002:     24 / 1218 loss=2.33, nll_loss=0.095, accuracy=19.5, wps=378.5, ups=1.88, wpb=197.2, bsz=8, num_updates=1243, lr=6.16491e-06, gnorm=2.854, clip=0, oom=0, loss_scale=128, train_wall=13, ppl=1.07, wall=719\n",
            "2020-02-14 22:19:48 | INFO | train | epoch 002:     49 / 1218 loss=2.329, nll_loss=0.097, accuracy=21.75, wps=353.8, ups=1.84, wpb=191.9, bsz=8, num_updates=1268, lr=6.07719e-06, gnorm=2.896, clip=0, oom=0, loss_scale=128, train_wall=27, ppl=1.07, wall=733\n",
            "2020-02-14 22:20:02 | INFO | train | epoch 002:     74 / 1218 loss=2.33, nll_loss=0.097, accuracy=21.105527877807617, wps=348, ups=1.81, wpb=192, bsz=8, num_updates=1293, lr=5.98947e-06, gnorm=2.927, clip=0, oom=0, loss_scale=128, train_wall=41, ppl=1.07, wall=747\n",
            "2020-02-14 22:20:16 | INFO | train | epoch 002:     99 / 1218 loss=2.33, nll_loss=0.097, accuracy=20.45169448852539, wps=347, ups=1.81, wpb=191.9, bsz=8, num_updates=1318, lr=5.90175e-06, gnorm=2.953, clip=0, oom=0, loss_scale=128, train_wall=55, ppl=1.07, wall=761\n",
            "2020-02-14 22:20:29 | INFO | train | epoch 002:    124 / 1218 loss=2.332, nll_loss=0.097, accuracy=20.0601806640625, wps=348.8, ups=1.81, wpb=192.4, bsz=8, num_updates=1343, lr=5.81404e-06, gnorm=2.95, clip=0, oom=0, loss_scale=128, train_wall=68, ppl=1.07, wall=774\n",
            "2020-02-14 22:20:43 | INFO | train | epoch 002:    149 / 1218 loss=2.331, nll_loss=0.097, accuracy=20.300752639770508, wps=349.4, ups=1.81, wpb=192.6, bsz=8, num_updates=1368, lr=5.72632e-06, gnorm=2.937, clip=0, oom=0, loss_scale=128, train_wall=82, ppl=1.07, wall=788\n",
            "2020-02-14 22:20:57 | INFO | train | epoch 002:    174 / 1218 loss=2.333, nll_loss=0.096, accuracy=19.8997859954834, wps=351.9, ups=1.81, wpb=194, bsz=8, num_updates=1393, lr=5.6386e-06, gnorm=2.938, clip=0, oom=0, loss_scale=128, train_wall=95, ppl=1.07, wall=802\n",
            "2020-02-14 22:21:11 | INFO | train | epoch 002:    199 / 1218 loss=2.331, nll_loss=0.096, accuracy=20.41327476501465, wps=351.8, ups=1.81, wpb=194.2, bsz=8, num_updates=1418, lr=5.55088e-06, gnorm=2.906, clip=0, oom=0, loss_scale=128, train_wall=109, ppl=1.07, wall=816\n",
            "2020-02-14 22:21:24 | INFO | train | epoch 002:    224 / 1218 loss=2.331, nll_loss=0.096, accuracy=19.977741241455078, wps=352, ups=1.81, wpb=194.1, bsz=8, num_updates=1443, lr=5.46316e-06, gnorm=2.88, clip=0, oom=0, loss_scale=128, train_wall=123, ppl=1.07, wall=829\n",
            "2020-02-14 22:21:38 | INFO | train | epoch 002:    249 / 1218 loss=2.332, nll_loss=0.096, accuracy=19.729595184326172, wps=352.1, ups=1.81, wpb=193.9, bsz=8, num_updates=1468, lr=5.37544e-06, gnorm=2.852, clip=0, oom=0, loss_scale=128, train_wall=136, ppl=1.07, wall=843\n",
            "2020-02-14 22:21:52 | INFO | train | epoch 002:    274 / 1218 loss=2.331, nll_loss=0.096, accuracy=19.708694458007812, wps=353.1, ups=1.82, wpb=194.2, bsz=8, num_updates=1493, lr=5.28772e-06, gnorm=2.824, clip=0, oom=0, loss_scale=128, train_wall=150, ppl=1.07, wall=857\n",
            "2020-02-14 22:22:05 | INFO | train | epoch 002:    299 / 1218 loss=2.331, nll_loss=0.096, accuracy=19.48268699645996, wps=352.9, ups=1.82, wpb=194.1, bsz=8, num_updates=1518, lr=5.2e-06, gnorm=2.804, clip=0, oom=0, loss_scale=128, train_wall=163, ppl=1.07, wall=870\n",
            "2020-02-14 22:22:19 | INFO | train | epoch 002:    324 / 1218 loss=2.331, nll_loss=0.096, accuracy=19.407007217407227, wps=352.4, ups=1.82, wpb=193.7, bsz=8, num_updates=1543, lr=5.11228e-06, gnorm=2.786, clip=0, oom=0, loss_scale=128, train_wall=177, ppl=1.07, wall=884\n",
            "2020-02-14 22:22:33 | INFO | train | epoch 002:    349 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.520915985107422, wps=352.1, ups=1.82, wpb=193.5, bsz=8, num_updates=1568, lr=5.02456e-06, gnorm=2.772, clip=0, oom=0, loss_scale=128, train_wall=190, ppl=1.07, wall=898\n",
            "2020-02-14 22:22:46 | INFO | train | epoch 002:    374 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.41942024230957, wps=353, ups=1.82, wpb=193.7, bsz=8, num_updates=1593, lr=4.93684e-06, gnorm=2.764, clip=0, oom=0, loss_scale=128, train_wall=204, ppl=1.07, wall=911\n",
            "2020-02-14 22:23:00 | INFO | train | epoch 002:    399 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.518299102783203, wps=352.8, ups=1.82, wpb=193.6, bsz=8, num_updates=1618, lr=4.84912e-06, gnorm=2.759, clip=0, oom=0, loss_scale=128, train_wall=217, ppl=1.07, wall=925\n",
            "2020-02-14 22:23:13 | INFO | train | epoch 002:    424 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.57609748840332, wps=353.4, ups=1.82, wpb=193.6, bsz=8, num_updates=1643, lr=4.7614e-06, gnorm=2.753, clip=0, oom=0, loss_scale=128, train_wall=230, ppl=1.07, wall=938\n",
            "2020-02-14 22:23:27 | INFO | train | epoch 002:    449 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.488462448120117, wps=352.8, ups=1.83, wpb=193.2, bsz=8, num_updates=1668, lr=4.67368e-06, gnorm=2.748, clip=0, oom=0, loss_scale=128, train_wall=244, ppl=1.07, wall=952\n",
            "2020-02-14 22:23:40 | INFO | train | epoch 002:    474 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.541744232177734, wps=353.1, ups=1.83, wpb=193.3, bsz=8, num_updates=1693, lr=4.58596e-06, gnorm=2.742, clip=0, oom=0, loss_scale=128, train_wall=257, ppl=1.07, wall=965\n",
            "2020-02-14 22:23:55 | INFO | train | epoch 002:    499 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.589693069458008, wps=352.7, ups=1.82, wpb=193.4, bsz=8, num_updates=1718, lr=4.49825e-06, gnorm=2.741, clip=0, oom=0, loss_scale=128, train_wall=271, ppl=1.07, wall=980\n",
            "2020-02-14 22:24:09 | INFO | train | epoch 002:    524 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.466285705566406, wps=352.2, ups=1.82, wpb=193.6, bsz=8, num_updates=1743, lr=4.41053e-06, gnorm=2.739, clip=0, oom=0, loss_scale=128, train_wall=285, ppl=1.07, wall=994\n",
            "2020-02-14 22:24:23 | INFO | train | epoch 002:    549 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.536046981811523, wps=351.1, ups=1.82, wpb=193.3, bsz=8, num_updates=1768, lr=4.32281e-06, gnorm=2.737, clip=0, oom=0, loss_scale=128, train_wall=300, ppl=1.07, wall=1008\n",
            "2020-02-14 22:24:36 | INFO | train | epoch 002:    574 / 1218 loss=2.329, nll_loss=0.096, accuracy=19.469219207763672, wps=351.7, ups=1.82, wpb=193.3, bsz=8, num_updates=1793, lr=4.23509e-06, gnorm=2.732, clip=0, oom=0, loss_scale=128, train_wall=313, ppl=1.07, wall=1021\n",
            "2020-02-14 22:24:50 | INFO | train | epoch 002:    599 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.366270065307617, wps=351.2, ups=1.82, wpb=192.9, bsz=8, num_updates=1818, lr=4.14737e-06, gnorm=2.725, clip=0, oom=0, loss_scale=128, train_wall=326, ppl=1.07, wall=1035\n",
            "2020-02-14 22:25:04 | INFO | train | epoch 002:    624 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.57174301147461, wps=351.1, ups=1.82, wpb=192.9, bsz=8, num_updates=1843, lr=4.05965e-06, gnorm=2.716, clip=0, oom=0, loss_scale=128, train_wall=340, ppl=1.07, wall=1049\n",
            "2020-02-14 22:25:17 | INFO | train | epoch 002:    649 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.549739837646484, wps=350.9, ups=1.82, wpb=192.8, bsz=8, num_updates=1868, lr=3.97193e-06, gnorm=2.707, clip=0, oom=0, loss_scale=128, train_wall=353, ppl=1.07, wall=1062\n",
            "2020-02-14 22:25:31 | INFO | train | epoch 002:    674 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.547897338867188, wps=350.4, ups=1.82, wpb=192.5, bsz=8, num_updates=1893, lr=3.88421e-06, gnorm=2.696, clip=0, oom=0, loss_scale=128, train_wall=367, ppl=1.07, wall=1076\n",
            "2020-02-14 22:25:45 | INFO | train | epoch 002:    699 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.510452270507812, wps=350.1, ups=1.82, wpb=192.3, bsz=8, num_updates=1918, lr=3.79649e-06, gnorm=2.684, clip=0, oom=0, loss_scale=128, train_wall=380, ppl=1.07, wall=1090\n",
            "2020-02-14 22:25:59 | INFO | train | epoch 002:    724 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.579092025756836, wps=350.1, ups=1.82, wpb=192.4, bsz=8, num_updates=1943, lr=3.70877e-06, gnorm=2.673, clip=0, oom=0, loss_scale=128, train_wall=394, ppl=1.07, wall=1104\n",
            "2020-02-14 22:26:13 | INFO | train | epoch 002:    749 / 1218 loss=2.329, nll_loss=0.097, accuracy=19.693180084228516, wps=350, ups=1.82, wpb=192.4, bsz=8, num_updates=1968, lr=3.62105e-06, gnorm=2.662, clip=0, oom=0, loss_scale=128, train_wall=408, ppl=1.07, wall=1118\n",
            "2020-02-14 22:26:26 | INFO | train | epoch 002:    774 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.832176208496094, wps=350.3, ups=1.82, wpb=192.5, bsz=8, num_updates=1993, lr=3.53333e-06, gnorm=2.653, clip=0, oom=0, loss_scale=128, train_wall=421, ppl=1.07, wall=1131\n",
            "2020-02-14 22:26:40 | INFO | train | epoch 002:    799 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.884321212768555, wps=350.5, ups=1.82, wpb=192.4, bsz=8, num_updates=2018, lr=3.44561e-06, gnorm=2.651, clip=0, oom=0, loss_scale=128, train_wall=434, ppl=1.07, wall=1145\n",
            "2020-02-14 22:26:53 | INFO | train | epoch 002:    824 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.978778839111328, wps=350.7, ups=1.82, wpb=192.5, bsz=8, num_updates=2043, lr=3.35789e-06, gnorm=2.644, clip=0, oom=0, loss_scale=128, train_wall=448, ppl=1.07, wall=1158\n",
            "2020-02-14 22:27:08 | INFO | train | epoch 002:    849 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.94997787475586, wps=350.1, ups=1.82, wpb=192.5, bsz=8, num_updates=2068, lr=3.27018e-06, gnorm=2.639, clip=0, oom=0, loss_scale=128, train_wall=462, ppl=1.07, wall=1173\n",
            "2020-02-14 22:27:21 | INFO | train | epoch 002:    874 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.06574249267578, wps=350.2, ups=1.82, wpb=192.5, bsz=8, num_updates=2093, lr=3.18246e-06, gnorm=2.633, clip=0, oom=0, loss_scale=128, train_wall=476, ppl=1.07, wall=1186\n",
            "2020-02-14 22:27:35 | INFO | train | epoch 002:    899 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.091705322265625, wps=350.5, ups=1.82, wpb=192.7, bsz=8, num_updates=2118, lr=3.09474e-06, gnorm=2.626, clip=0, oom=0, loss_scale=128, train_wall=489, ppl=1.07, wall=1200\n",
            "2020-02-14 22:27:49 | INFO | train | epoch 002:    924 / 1218 loss=2.328, nll_loss=0.097, accuracy=20.143301010131836, wps=350.6, ups=1.82, wpb=192.8, bsz=8, num_updates=2143, lr=3.00702e-06, gnorm=2.619, clip=0, oom=0, loss_scale=128, train_wall=503, ppl=1.07, wall=1214\n",
            "2020-02-14 22:28:03 | INFO | train | epoch 002:    949 / 1218 loss=2.328, nll_loss=0.096, accuracy=20.231670379638672, wps=350.6, ups=1.82, wpb=193, bsz=8, num_updates=2168, lr=2.9193e-06, gnorm=2.612, clip=0, oom=0, loss_scale=128, train_wall=517, ppl=1.07, wall=1228\n",
            "2020-02-14 22:28:17 | INFO | train | epoch 002:    974 / 1218 loss=2.327, nll_loss=0.096, accuracy=20.238554000854492, wps=350.4, ups=1.82, wpb=193, bsz=8, num_updates=2193, lr=2.83158e-06, gnorm=2.605, clip=0, oom=0, loss_scale=128, train_wall=531, ppl=1.07, wall=1242\n",
            "2020-02-14 22:28:31 | INFO | train | epoch 002:    999 / 1218 loss=2.327, nll_loss=0.096, accuracy=20.232587814331055, wps=350.2, ups=1.82, wpb=192.9, bsz=8, num_updates=2218, lr=2.74386e-06, gnorm=2.6, clip=0, oom=0, loss_scale=128, train_wall=545, ppl=1.07, wall=1256\n",
            "2020-02-14 22:28:45 | INFO | train | epoch 002:   1024 / 1218 loss=2.327, nll_loss=0.096, accuracy=20.275711059570312, wps=350.2, ups=1.82, wpb=192.9, bsz=8, num_updates=2243, lr=2.65614e-06, gnorm=2.596, clip=0, oom=0, loss_scale=128, train_wall=558, ppl=1.07, wall=1270\n",
            "2020-02-14 22:28:59 | INFO | train | epoch 002:   1049 / 1218 loss=2.327, nll_loss=0.096, accuracy=20.376325607299805, wps=350.2, ups=1.82, wpb=192.9, bsz=8, num_updates=2268, lr=2.56842e-06, gnorm=2.608, clip=0, oom=0, loss_scale=128, train_wall=572, ppl=1.07, wall=1284\n",
            "2020-02-14 22:29:13 | INFO | train | epoch 002:   1074 / 1218 loss=2.326, nll_loss=0.096, accuracy=20.530418395996094, wps=350, ups=1.81, wpb=192.9, bsz=8, num_updates=2293, lr=2.4807e-06, gnorm=2.621, clip=0, oom=0, loss_scale=128, train_wall=586, ppl=1.07, wall=1298\n",
            "2020-02-14 22:29:26 | INFO | train | epoch 002:   1099 / 1218 loss=2.326, nll_loss=0.097, accuracy=20.51835823059082, wps=349.9, ups=1.82, wpb=192.8, bsz=8, num_updates=2318, lr=2.39298e-06, gnorm=2.633, clip=0, oom=0, loss_scale=128, train_wall=599, ppl=1.07, wall=1311\n",
            "2020-02-14 22:29:40 | INFO | train | epoch 002:   1124 / 1218 loss=2.326, nll_loss=0.096, accuracy=20.562410354614258, wps=350, ups=1.82, wpb=192.8, bsz=8, num_updates=2343, lr=2.30526e-06, gnorm=2.641, clip=0, oom=0, loss_scale=128, train_wall=613, ppl=1.07, wall=1325\n",
            "2020-02-14 22:29:54 | INFO | train | epoch 002:   1149 / 1218 loss=2.326, nll_loss=0.096, accuracy=20.57192611694336, wps=350.1, ups=1.81, wpb=192.9, bsz=8, num_updates=2368, lr=2.21754e-06, gnorm=2.642, clip=0, oom=0, loss_scale=128, train_wall=627, ppl=1.07, wall=1339\n",
            "2020-02-14 22:30:07 | INFO | train | epoch 002:   1174 / 1218 loss=2.326, nll_loss=0.096, accuracy=20.581035614013672, wps=350.2, ups=1.82, wpb=192.9, bsz=8, num_updates=2393, lr=2.12982e-06, gnorm=2.64, clip=0, oom=0, loss_scale=128, train_wall=640, ppl=1.07, wall=1353\n",
            "2020-02-14 22:30:21 | INFO | train | epoch 002:   1199 / 1218 loss=2.326, nll_loss=0.096, accuracy=20.74606704711914, wps=350.3, ups=1.82, wpb=192.9, bsz=8, num_updates=2418, lr=2.04211e-06, gnorm=2.638, clip=0, oom=0, loss_scale=128, train_wall=654, ppl=1.07, wall=1366\n",
            "2020-02-14 22:30:31 | INFO | train | epoch 002 | loss 2.326 | nll_loss 0.096 | accuracy 20.747356414794922 | wps 350.3 | ups 1.82 | wpb 193 | bsz 8 | num_updates 2436 | lr 1.97895e-06 | gnorm 2.639 | clip 0 | oom 0 | loss_scale 128 | train_wall 664 | ppl 1.07 | wall 1376\n",
            "2020-02-14 22:30:51 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 2.325 | nll_loss 0.097 | accuracy 17.854217529296875 | wps 1471.6 | wpb 191 | bsz 8 | ppl 1.07 | num_updates 2436 | best_accuracy 17.854217529296875\n",
            "2020-02-14 22:30:54 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 2436 updates, score 17.854217529296875) (writing took 2.1588253749998785 seconds)\n",
            "2020-02-14 22:31:07 | INFO | train | epoch 003:     24 / 1218 loss=2.331, nll_loss=0.096, accuracy=20.0, wps=357.7, ups=1.83, wpb=194.5, bsz=8, num_updates=2461, lr=1.89123e-06, gnorm=2.887, clip=0, oom=0, loss_scale=128, train_wall=14, ppl=1.07, wall=1412\n",
            "2020-02-14 22:31:21 | INFO | train | epoch 003:     49 / 1218 loss=2.328, nll_loss=0.097, accuracy=19.25, wps=351.9, ups=1.83, wpb=192.5, bsz=8, num_updates=2486, lr=1.80351e-06, gnorm=2.773, clip=0, oom=0, loss_scale=128, train_wall=27, ppl=1.07, wall=1426\n",
            "2020-02-14 22:31:35 | INFO | train | epoch 003:     74 / 1218 loss=2.33, nll_loss=0.097, accuracy=20.33333396911621, wps=355, ups=1.84, wpb=192.9, bsz=8, num_updates=2511, lr=1.71579e-06, gnorm=2.792, clip=0, oom=0, loss_scale=128, train_wall=41, ppl=1.07, wall=1440\n",
            "2020-02-14 22:31:48 | INFO | train | epoch 003:     99 / 1218 loss=2.325, nll_loss=0.097, accuracy=21.0, wps=357, ups=1.85, wpb=192.8, bsz=8, num_updates=2536, lr=1.62807e-06, gnorm=2.775, clip=0, oom=0, loss_scale=128, train_wall=54, ppl=1.07, wall=1453\n",
            "2020-02-14 22:32:02 | INFO | train | epoch 003:    124 / 1218 loss=2.325, nll_loss=0.097, accuracy=21.399999618530273, wps=353.9, ups=1.85, wpb=191.7, bsz=8, num_updates=2561, lr=1.54035e-06, gnorm=2.899, clip=0, oom=0, loss_scale=128, train_wall=67, ppl=1.07, wall=1467\n",
            "2020-02-14 22:32:15 | INFO | train | epoch 003:    149 / 1218 loss=2.326, nll_loss=0.097, accuracy=21.25, wps=354.6, ups=1.84, wpb=192.7, bsz=8, num_updates=2586, lr=1.45263e-06, gnorm=2.968, clip=0, oom=0, loss_scale=128, train_wall=81, ppl=1.07, wall=1480\n",
            "2020-02-14 22:32:29 | INFO | train | epoch 003:    174 / 1218 loss=2.325, nll_loss=0.097, accuracy=21.071428298950195, wps=354.7, ups=1.84, wpb=192.5, bsz=8, num_updates=2611, lr=1.36491e-06, gnorm=2.936, clip=0, oom=0, loss_scale=128, train_wall=94, ppl=1.07, wall=1494\n",
            "2020-02-14 22:32:42 | INFO | train | epoch 003:    199 / 1218 loss=2.323, nll_loss=0.097, accuracy=21.0625, wps=354.5, ups=1.84, wpb=192.5, bsz=8, num_updates=2636, lr=1.27719e-06, gnorm=3.014, clip=0, oom=0, loss_scale=128, train_wall=108, ppl=1.07, wall=1507\n",
            "2020-02-14 22:32:56 | INFO | train | epoch 003:    224 / 1218 loss=2.323, nll_loss=0.096, accuracy=21.33333396911621, wps=354.6, ups=1.84, wpb=192.8, bsz=8, num_updates=2661, lr=1.18947e-06, gnorm=3.212, clip=0, oom=0, loss_scale=128, train_wall=121, ppl=1.07, wall=1521\n",
            "2020-02-14 22:33:10 | INFO | train | epoch 003:    249 / 1218 loss=2.322, nll_loss=0.096, accuracy=21.450000762939453, wps=356, ups=1.84, wpb=193.2, bsz=8, num_updates=2686, lr=1.10175e-06, gnorm=3.243, clip=0, oom=0, loss_scale=128, train_wall=134, ppl=1.07, wall=1535\n",
            "2020-02-14 22:33:23 | INFO | train | epoch 003:    274 / 1218 loss=2.319, nll_loss=0.096, accuracy=21.727272033691406, wps=356.2, ups=1.84, wpb=193.3, bsz=8, num_updates=2711, lr=1.01404e-06, gnorm=3.301, clip=0, oom=0, loss_scale=128, train_wall=148, ppl=1.07, wall=1548\n",
            "2020-02-14 22:33:36 | INFO | train | epoch 003:    299 / 1218 loss=2.317, nll_loss=0.096, accuracy=21.83333396911621, wps=357.1, ups=1.85, wpb=193.5, bsz=8, num_updates=2736, lr=9.26316e-07, gnorm=3.404, clip=0, oom=0, loss_scale=128, train_wall=161, ppl=1.07, wall=1561\n",
            "2020-02-14 22:33:50 | INFO | train | epoch 003:    324 / 1218 loss=2.316, nll_loss=0.096, accuracy=21.884614944458008, wps=357.6, ups=1.85, wpb=193.5, bsz=8, num_updates=2761, lr=8.38596e-07, gnorm=3.515, clip=0, oom=0, loss_scale=128, train_wall=174, ppl=1.07, wall=1575\n",
            "2020-02-14 22:34:03 | INFO | train | epoch 003:    349 / 1218 loss=2.315, nll_loss=0.096, accuracy=22.23811149597168, wps=357.6, ups=1.85, wpb=193.6, bsz=8, num_updates=2786, lr=7.50877e-07, gnorm=3.633, clip=0, oom=0, loss_scale=128, train_wall=188, ppl=1.07, wall=1588\n",
            "2020-02-14 22:34:17 | INFO | train | epoch 003:    374 / 1218 loss=2.314, nll_loss=0.096, accuracy=22.422422409057617, wps=357.2, ups=1.84, wpb=193.7, bsz=8, num_updates=2811, lr=6.63158e-07, gnorm=3.734, clip=0, oom=0, loss_scale=128, train_wall=201, ppl=1.07, wall=1602\n",
            "2020-02-14 22:34:31 | INFO | train | epoch 003:    399 / 1218 loss=2.315, nll_loss=0.096, accuracy=22.427274703979492, wps=356.7, ups=1.84, wpb=193.7, bsz=8, num_updates=2836, lr=5.75439e-07, gnorm=3.784, clip=0, oom=0, loss_scale=128, train_wall=215, ppl=1.07, wall=1616\n",
            "2020-02-14 22:34:45 | INFO | train | epoch 003:    424 / 1218 loss=2.315, nll_loss=0.096, accuracy=22.402118682861328, wps=355.3, ups=1.84, wpb=193.3, bsz=8, num_updates=2861, lr=4.87719e-07, gnorm=3.815, clip=0, oom=0, loss_scale=128, train_wall=229, ppl=1.07, wall=1630\n",
            "2020-02-14 22:34:59 | INFO | train | epoch 003:    449 / 1218 loss=2.315, nll_loss=0.096, accuracy=22.463163375854492, wps=355, ups=1.83, wpb=193.5, bsz=8, num_updates=2886, lr=4e-07, gnorm=3.825, clip=0, oom=0, loss_scale=128, train_wall=243, ppl=1.07, wall=1644\n",
            "2020-02-14 22:35:13 | INFO | train | epoch 003:    474 / 1218 loss=2.315, nll_loss=0.096, accuracy=22.517776489257812, wps=354.1, ups=1.83, wpb=193.4, bsz=8, num_updates=2911, lr=3.12281e-07, gnorm=3.838, clip=0, oom=0, loss_scale=128, train_wall=257, ppl=1.07, wall=1658\n",
            "2020-02-14 22:35:28 | INFO | train | epoch 003:    499 / 1218 loss=2.315, nll_loss=0.096, accuracy=22.416812896728516, wps=353.5, ups=1.83, wpb=193.5, bsz=8, num_updates=2936, lr=2.24561e-07, gnorm=3.846, clip=0, oom=0, loss_scale=128, train_wall=271, ppl=1.07, wall=1673\n",
            "2020-02-14 22:35:41 | INFO | train | epoch 003:    524 / 1218 loss=2.316, nll_loss=0.096, accuracy=22.49225616455078, wps=353.5, ups=1.83, wpb=193.3, bsz=8, num_updates=2961, lr=1.36842e-07, gnorm=3.845, clip=0, oom=0, loss_scale=128, train_wall=284, ppl=1.07, wall=1686\n",
            "2020-02-14 22:35:55 | INFO | train | epoch 003:    549 / 1218 loss=2.316, nll_loss=0.096, accuracy=22.6063232421875, wps=353.2, ups=1.83, wpb=193.1, bsz=8, num_updates=2986, lr=4.91228e-08, gnorm=3.844, clip=0, oom=0, loss_scale=128, train_wall=298, ppl=1.07, wall=1700\n",
            "2020-02-14 22:36:02 | INFO | train | epoch 003 | loss 2.316 | nll_loss 0.096 | accuracy 22.510534286499023 | wps 353.2 | ups 1.83 | wpb 193.1 | bsz 8 | num_updates 3000 | lr 0 | gnorm 3.843 | clip 0 | oom 0 | loss_scale 128 | train_wall 305 | ppl 1.07 | wall 1707\n",
            "2020-02-14 22:36:22 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 2.329 | nll_loss 0.097 | accuracy 17.77231788635254 | wps 1479.2 | wpb 191 | bsz 8 | ppl 1.07 | num_updates 3000 | best_accuracy 17.854217529296875\n",
            "2020-02-14 22:36:22 | INFO | fairseq_cli.train | done training in 1718.6 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X78WLZF-SOhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}